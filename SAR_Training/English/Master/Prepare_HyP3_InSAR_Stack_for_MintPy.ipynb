{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "\n",
    "# Preparing a HyP3 InSAR Stack for MintPy\n",
    "\n",
    "**Author**: Alex Lewandowski; University of Alaska Fairbanks\n",
    " \n",
    "Based on [prep_hyp3_for_mintpy.ipynb](https://github.com/ASFHyP3/hyp3-docs) by Jiang Zhu; University of Alaska Fairbanks\n",
    "\n",
    "<img src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" />\n",
    "\n",
    "**Important Note about JupyterHub**\n",
    "Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%javascript\n",
    "var kernel = Jupyter.notebook.kernel;\n",
    "var command = [\"notebookUrl = \",\n",
    "               \"'\", window.location, \"'\" ].join('')\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/insar_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"insar_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"insar_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"insar_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Relevant Python Packages\n",
    "\n",
    "In this notebook we will use the following scientific libraries:\n",
    "- [GDAL](https://www.gdal.org/) is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.\n",
    "\n",
    "**Our first step is to import gdal and other needed packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from osgeo import gdal\n",
    "import pyproj\n",
    "\n",
    "import asf_notebook as asfn\n",
    "\n",
    "from hyp3_sdk import Batch, HyP3\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Your Own Data Stack Into the Notebook\n",
    "\n",
    "This notebook assumes that you've created an InSAR data stack over an area of interest using the [Alaska Satellite Facility's](https://www.asf.alaska.edu/) value-added product system HyP3, available via [ASF Data Search/Vertex](https://search.asf.alaska.edu/). HyP3 is an ASF service used to prototype value added products and provide them to users to collect feedback.\n",
    "\n",
    "We will retrieve HyP3 data via the hyp3_sdk. As both HyP3 and the Notebook environment sit in the [Amazon Web Services (AWS)](https://aws.amazon.com/) cloud, data transfer is quick and cost effective.\n",
    "\n",
    "Before downloading anything, create an analysis directory to hold your data.\n",
    "\n",
    "**Select or create a working directory for the analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    data_dir = Path(asfn.input_path(f\"\\nPlease enter the name of a directory in which to store your data for this analysis.\"))\n",
    "    if data_dir.is_dir():\n",
    "        contents = data_dir.glob('*')\n",
    "        if len(list(contents)) > 0:\n",
    "            choice = asfn.handle_old_data(data_dir, list(contents))\n",
    "            if choice == 1:\n",
    "                shutil.rmtree(data_dir)\n",
    "                data_dir.mkdir()\n",
    "                break\n",
    "            elif choice == 2:\n",
    "                break\n",
    "            else:\n",
    "                clear_output()\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        data_dir.mkdir()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define absolute path to  analysis directory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_directory = Path.cwd().joinpath(data_dir)\n",
    "print(f\"analysis_directory: {analysis_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a HyP3 object and authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hyp3 = HyP3(prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List projects containing active InSAR products and select one:**\n",
    "\n",
    "Your HyP3 InSAR project should include:\n",
    "- DEMs\n",
    "- Incidence Angle Maps\n",
    "\n",
    "*DEMs and Inc Angle Maps are available as options when submitting a HyP3 project*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hyp3_info = hyp3.my_info()\n",
    "active_projects = dict()\n",
    "\n",
    "for project in my_hyp3_info['job_names']:\n",
    "    batch = Batch()\n",
    "    batch = hyp3.find_jobs(name=project, job_type='INSAR_GAMMA').filter_jobs(running=False, include_expired=False)\n",
    "    if len(batch) > 0:\n",
    "        active_projects.update({batch.jobs[0].name: batch})\n",
    "        \n",
    "if len(active_projects) > 0:\n",
    "    display(Markdown(\"<text style='color:darkred;'>Note: After selecting a project, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:darkred;'>Otherwise, you will rerun this code cell.</text>\"))\n",
    "    print('\\nSelect a Project:')\n",
    "    project_select = asfn.select_parameter(active_projects)\n",
    "\n",
    "project_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a date range of products to download:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = project_select.value\n",
    "\n",
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a date range, you should select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you may simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Date Range:')\n",
    "dates = asfn.get_job_dates(jobs)\n",
    "date_picker = asfn.gui_date_picker(dates)\n",
    "date_picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the selected date range and remove products falling outside of it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = asfn.get_slider_vals(date_picker)\n",
    "date_range[0] = date_range[0].date()\n",
    "date_range[1] = date_range[1].date()\n",
    "print(f\"Date Range: {str(date_range[0])} to {str(date_range[1])}\")\n",
    "jobs = asfn.filter_jobs_by_date(jobs, date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather the available paths and orbit directions for the remaining products:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'><text style='font-size:150%;'>This may take some time for projects containing many jobs...</text></text>\"))\n",
    "jobs = asfn.get_paths_orbits(jobs)\n",
    "paths = set()\n",
    "orbit_directions = set()\n",
    "for p in jobs:\n",
    "    paths.add(p.path)\n",
    "    orbit_directions.add(p.orbit_direction)\n",
    "display(Markdown(f\"<text style=color:blue><text style='font-size:175%;'>Done.</text></text>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Select a path:**\n",
    "\n",
    "This notebook does not currently support merging InSAR products in multiple paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a path, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Path:')\n",
    "path_choice = asfn.select_parameter(paths)\n",
    "path_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the selected flight path/s:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_path = path_choice.value\n",
    "if flight_path:\n",
    "    if flight_path:\n",
    "        print(f\"Flight Path: {flight_path}\")\n",
    "    else:\n",
    "        print('Flight Path: All Paths')\n",
    "else:\n",
    "    print(\"WARNING: You must select a flight path in the previous cell, then rerun this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select an orbit direction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(orbit_directions) > 1:\n",
    "    display(Markdown(\"<text style='color:red;'>Note: After selecting a flight direction, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:red;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Flight Direction:')\n",
    "direction_choice = asfn.select_parameter(orbit_directions, 'Direction:')\n",
    "direction_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the selected orbit direction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = direction_choice.value\n",
    "print(f\"Orbit Direction: {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter jobs by path and orbit direction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = asfn.filter_jobs_by_path(jobs, [flight_path])\n",
    "jobs = asfn.filter_jobs_by_orbit(jobs, direction)\n",
    "print(f\"There are {len(jobs)} products to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the products, unzip them into a directory named after the product type, and delete the zip files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nProject: {jobs.jobs[0].name}\")\n",
    "project_zips = jobs.download_files(analysis_directory)\n",
    "for z in project_zips:\n",
    "    asfn.asf_unzip(str(analysis_directory), str(z))\n",
    "    z.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Confirm Presence of DEMS and Incidence Angle Maps\n",
    "\n",
    "These are optional addon products in HyP3, which are necessary for MintPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dems = list(analysis_directory.glob('*/*dem.tif'))\n",
    "inc_maps = list(analysis_directory.glob('*/*inc_map.tif'))\n",
    "\n",
    "if len(dems) > 0 and len(inc_maps) == len(jobs):\n",
    "    print(\"Success: Found at least 1 DEM and an incidence angle map for every job.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Failed to find at least 1 DEM and an incidence angle map for every job. \\\n",
    "    \\nYou will not be able to successfully run a MintPy time-series unless your reorder your HyP3 project \\\n",
    "with DEMS and Incidence Angle Maps included.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Subset the Stack and Cleanup Unused Files\n",
    "\n",
    "**Subset the stack to the largest aoi covered by all input files and delete unneeded files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = list(analysis_directory.glob('*/*.tif'))\n",
    "fnames.sort()\n",
    "\n",
    "# determine the largest area covered by all input files\n",
    "corners = [gdal.Info(str(f), format='json')['cornerCoordinates'] for f in fnames]\n",
    "ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "\n",
    "# clip the files\n",
    "# regex = '(?<=_)(corr|unw_phase|water_mask|dem|lv_theta|inc_map|inc_map_ell|amp)(?=.tif)'\n",
    "regex = '.tif'\n",
    "for fname in fnames:\n",
    "    if re.search(regex, str(fname)):\n",
    "        fname_out = fname.parent.joinpath(Path(f\"{fname.stem}_clip{fname.suffix}\"))\n",
    "        gdal.Translate(destName=str(fname_out), srcDS=str(fname), projWin=[ulx, uly, lrx, lry])\n",
    "        fname.unlink()\n",
    "        \n",
    "# remove the *.xml, png, and *.kmz files\n",
    "for pattern in [\"xml\",\"png\",\"kmz\",\"md.txt\"]:\n",
    "    unneeded_files = analysis_directory.glob(f\"*/*.{pattern}\")\n",
    "    for file in unneeded_files:\n",
    "        file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": true
   },
   "source": [
    "**Subset the stack to a smaller AOI or skip the rest of this section and proceed to section 4 for a link to the MintPy_Time_Series_From_Prepared_Data_Stack notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = f\"{analysis_directory}/raster_stack.vrt\"\n",
    "amp = list(analysis_directory.glob('*/*_amp_clip.tif'))[0]\n",
    "!gdalbuildvrt -separate $image_file -overwrite $amp\n",
    "img = gdal.Open(image_file)\n",
    "rasterstack = img.ReadAsArray()\n",
    "\n",
    "fig_xsize = 7.5\n",
    "fig_ysize = 7.5\n",
    "aoi = asfn.AOI_Selector(rasterstack, fig_xsize, fig_ysize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotrans = img.GetGeoTransform()\n",
    "\n",
    "def geolocation(x, y, geotrans):\n",
    "    return [geotrans[0]+x*geotrans[1], geotrans[3]+y*geotrans[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ul = geolocation(aoi.x1, aoi.y1, geotrans)\n",
    "    lr = geolocation(aoi.x2, aoi.y2, geotrans)\n",
    "#     print(f\"aoi_coords in EPSG {utm}\")\n",
    "    print(f\"upper left corner: {ul}\")\n",
    "    print(f\"lower right corner: {lr}\")\n",
    "except TypeError:\n",
    "    print('TypeError')\n",
    "    display(Markdown(f'<text style=color:red>This error may occur if an AOI was not selected.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that the square tool icon in the AOI selector menu is <b>NOT</b> the selection tool. It is the zoom tool.</text>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = list(analysis_directory.glob('*/*clip.tif'))\n",
    "clips.sort()\n",
    "\n",
    "for i, fname in enumerate(clips):\n",
    "    fname.rename(fnames[i])\n",
    "    gdal.Translate(destName=str(fname), srcDS=str(fnames[i]), projWin=[ul[0], ul[1], lr[0], lr[1]])\n",
    "    fnames[i].unlink() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Proceed to the MintPy Time-Series Notebook\n",
    "\n",
    "**Run the code cell below for a link to the MintPy_Time_Series_From_Prepared_Data_Stack notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f'<text style=color:green> Open <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/notebooks/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb\" target=\"_blank\"> MintPy_Time_Series_From_Prepared_Data_Stack.ipynb </a>to run an InSAR time-series analysis on your data using MintPy</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb - Version 1.1.0 - September 2021\n",
    "    <ul>\n",
    "        <li>Add DEM and Incidence Angle Map check</li>\n",
    "        <li>Add AOI subsetting</li>\n",
    "        <li>Link to MintPy_Time_Series_From_Prepared_Data_Stack.ipynb</li>\n",
    "    </ul>\n",
    "    </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insar_analysis",
   "language": "python",
   "name": "conda-env-.local-insar_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
