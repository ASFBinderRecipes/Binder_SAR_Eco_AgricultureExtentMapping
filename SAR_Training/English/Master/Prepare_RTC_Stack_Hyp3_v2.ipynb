{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Prepare a SAR Data Stack</b><img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer and Alex Lewandowski; University of Alaska Fairbanks </b> <br>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This notebook downloads an ASF-Hyp3 subscription and prepares a deep multi-temporal SAR image data stack for use in other notebooks.</font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color=\"darkred\"> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "</font>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Our first step is to import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import json # for loads\n",
    "import html\n",
    "import shutil\n",
    "import re\n",
    "import gdal\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display, clear_output, Markdown\n",
    "from ipywidgets import interact, Button, HBox, Layout\n",
    "from asf_notebook import new_directory\n",
    "from asf_notebook import asf_unzip\n",
    "from asf_notebook import path_exists\n",
    "from asf_notebook import get_RTC_polarizations\n",
    "from asf_notebook import gui_date_picker\n",
    "from asf_notebook import date_from_product_name\n",
    "from asf_notebook import select_parameter\n",
    "from asf_notebook import select_mult_parameters\n",
    "from asf_notebook import get_slider_vals\n",
    "from asf_notebook import input_path\n",
    "from asf_notebook import handle_old_data\n",
    "from asf_notebook import get_power_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Your Own Data Stack Into the Notebook </b> </font> \n",
    "\n",
    "<font size=\"3\"> This notebook assumes that you've created your own data stack over your personal area of interest using the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility's</a> value-added product system <a href=\"http://hyp3.asf.alaska.edu/\" target=\"_blank\">HyP3</a>. HyP3 is an environment that is used by ASF to prototype value added products and provide them to users to collect feedback. \n",
    "\n",
    "This lab expects <a href=\"https://media.asf.alaska.edu/uploads/RTC/rtc_atbd_v1.2_final.pdf\" target=\"_blank\">Radiometric Terrain Corrected</a> (RTC) image products as input, so be sure to select an RTC process when creating the subscription for your input data within HyP. Prefer a unique orbit geometry **(choose ascending or descending, not both)** to keep geometric differences between images low. \n",
    "\n",
    "We will retrieve HyP3 data via the HyP3 API. As both HyP3 and the Notebook environment sit in the <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Services (AWS)</a> cloud, data transfer is quick and cost effective.</font> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> Before we download anything, create a working directory for this analysis and change into it. \n",
    "<br><br>\n",
    "<b>Select or create a working directory for the analysis:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    data_dir = input_path(f\"\\nPlease enter the name of a directory in which to store your data for this analysis.\")\n",
    "    if os.path.exists(data_dir):\n",
    "        contents = glob.glob(f'{data_dir}/*')\n",
    "        if len(contents) > 0:\n",
    "            choice = handle_old_data(data_dir, contents)\n",
    "            if choice == 1:\n",
    "                shutil.rmtree(data_dir)\n",
    "                os.mkdir(data_dir)\n",
    "                break\n",
    "            elif choice == 2:\n",
    "                break\n",
    "            else:\n",
    "                clear_output()\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        os.mkdir(data_dir)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Change into the analysis directory:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_directory = f\"{os.getcwd()}/{data_dir}\"\n",
    "os.chdir(analysis_directory)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a folder in which to download your RTC products.</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_path = \"rtc_products\"\n",
    "new_directory(rtc_path)\n",
    "products_path = f\"{analysis_directory}/{rtc_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### New Functions for HyP3v2 #####\n",
    "\n",
    "from datetime import datetime, date\n",
    "from getpass import getpass\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from hyp3_sdk import HyP3\n",
    "from hyp3_sdk import Job\n",
    "\n",
    "def hyp3_auth() -> HyP3:\n",
    "    exception = None\n",
    "    while True:\n",
    "        if exception:\n",
    "            print(exception)\n",
    "            print(\"Please try again.\")\n",
    "        username = input(\"Username: \")\n",
    "        password = getpass(\"Password: \")\n",
    "        try:\n",
    "            hyp3 = HyP3(username=username, password=password)\n",
    "            clear_output()\n",
    "            print(\"Authentication Successful\")\n",
    "            return hyp3\n",
    "        except Exception as e:\n",
    "            exception = e\n",
    "            clear_output()\n",
    "            \n",
    "def get_projects(hyp3):\n",
    "    jobs = hyp3.find_jobs()\n",
    "    subs = dict()\n",
    "    for job in jobs.jobs:\n",
    "        if job.name not in subs:\n",
    "            subs.update({job.name: [job]})\n",
    "        else:\n",
    "            subs[job.name].append(job)\n",
    "    return subs\n",
    "            \n",
    "def get_job_dates(jobs: List[str]) -> List[str]:\n",
    "    dates = set()\n",
    "    for job in jobs:\n",
    "        for granule in job.job_parameters['granules']:\n",
    "            dates.add(date_from_product_name(granule).split('T')[0])\n",
    "    return list(dates)\n",
    "\n",
    "def cull_jobs_by_date(jobs: List[Job], date_range: list) -> List[Job]:\n",
    "    for job in jobs:\n",
    "        for granule in job.job_parameters['granules']:\n",
    "            dt = date_from_product_name(granule).split('T')[0]\n",
    "            if (date(int(dt[:4]), int(dt[4:6]), int(dt[-2:])) < date_range[0] or\n",
    "            date(int(dt[:4]), int(dt[4:6]), int(dt[-2:])) > date_range[1]):\n",
    "                jobs.remove(job)\n",
    "                break\n",
    "    return jobs\n",
    "\n",
    "def get_paths_orbits(jobs: List[Job]):\n",
    "    vertex_API_URL = \"https://api.daac.asf.alaska.edu/services/search/param\"\n",
    "    for job in jobs:\n",
    "        granule = job.job_parameters['granules'][0]\n",
    "        parameters = [('granule_list', granule), ('output', 'json')]\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                vertex_API_URL,\n",
    "                params=parameters,\n",
    "                stream=True\n",
    "            )\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            sys.exit(1)               \n",
    "        json_response = None\n",
    "        if response.json()[0]:\n",
    "            json_response = response.json()[0][0]\n",
    "            try:\n",
    "                job.path = json_response['track']\n",
    "                job.orbit_direction = json_response['flightDirection']\n",
    "            except TypeError:\n",
    "                print(f\"TypeError: json_response for {granule_name}: {json_response}\")\n",
    "                pass\n",
    "    return jobs\n",
    "\n",
    "def cull_jobs_by_path(jobs: List[Job], paths: List[str]) -> List[Job]:\n",
    "    if 'All Paths' in paths:\n",
    "        return jobs\n",
    "    for job in jobs:\n",
    "        if job.path not in paths:\n",
    "            jobs.remove(job)\n",
    "    return jobs\n",
    "\n",
    "def cull_jobs_by_orbit(jobs: List[Job], orbit_direction: str) -> List[Job]:\n",
    "    for job in jobs:\n",
    "        if job.orbit_direction != orbit_direction:\n",
    "            jobs.remove(job)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a HyP3 object and authenticate</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp3 = hyp3_auth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>List your projects and select one:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = get_projects(hyp3)\n",
    "\n",
    "if len(projects) > 0:\n",
    "    display(Markdown(\"<text style='color:darkred;'>Note: After selecting a project, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:darkred;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "    print('\\nSelect a Project:')\n",
    "    project_select = select_parameter(projects)\n",
    "    \n",
    "project_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a date range of products to download:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = project_select.value\n",
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a date range, you should select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you may simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Date Range:')\n",
    "dates = get_job_dates(project)\n",
    "date_picker = gui_date_picker(dates)\n",
    "date_picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected date range and remove products falling outside of it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_range = get_slider_vals(date_picker)\n",
    "date_range[0] = date_range[0].date()\n",
    "date_range[1] = date_range[1].date()\n",
    "print(f\"Date Range: {str(date_range[0])} to {str(date_range[1])}\")\n",
    "project = cull_jobs_by_date(project, date_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Gather the available paths and orbit directions for the remaining products:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = get_paths_orbits(project)\n",
    "paths = set()\n",
    "orbit_directions = set()\n",
    "for p in project:\n",
    "    paths.add(p.path)\n",
    "    orbit_directions.add(p.orbit_direction)\n",
    "paths.add('All Paths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Select a path or paths (use shift or ctrl to select multiple paths):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:darkred;'>Note: After selecting a path, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "display(Markdown(\"<text style='color:darkred;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Path:')\n",
    "path_choice = select_mult_parameters(paths)\n",
    "path_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected flight path/s:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_path = path_choice.value\n",
    "if flight_path:\n",
    "    if flight_path:\n",
    "        print(f\"Flight Path: {flight_path}\")\n",
    "    else:\n",
    "        print('Flight Path: All Paths')\n",
    "else:\n",
    "    print(\"WARNING: You must select a flight path in the previous cell, then rerun this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select an orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(orbit_directions) > 1:\n",
    "    display(Markdown(\"<text style='color:red;'>Note: After selecting a flight direction, you must select the next cell before hitting the 'Run' button or typing Shift/Enter.</text>\"))\n",
    "    display(Markdown(\"<text style='color:red;'>Otherwise, you will simply rerun this code cell.</text>\"))\n",
    "print('\\nSelect a Flight Direction:')\n",
    "direction_choice = select_parameter(orbit_directions, 'Direction:')\n",
    "direction_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = direction_choice.value\n",
    "print(f\"Orbit Direction: {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Filter jobs by path and orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cull_jobs_by_path(project, flight_path)\n",
    "cull_jobs_by_orbit(project, direction)\n",
    "print(f\"There are {len(project)} products to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Download the products, unzip them into the rtc_products directory, and delete the zip files:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if path_exists(products_path):\n",
    "    product_count = 1\n",
    "    print(f\"\\nProject: {project[0].name}\")\n",
    "    for job in project:\n",
    "        print(f\"\\nProduct Number {product_count} of {len(project)}:\")\n",
    "        product_count += 1\n",
    "        product = job.files[0]['url'].split('/')[4]\n",
    "        filename = f\"{products_path}/{product}\"\n",
    "        # if not already present, we need to download and unzip products\n",
    "        if not os.path.exists(f\"{filename.split('.zip')[0]}/\"):\n",
    "            print(\n",
    "                f\"\\n{product} is not present.\\nDownloading from {job.files[0]['url']}\")\n",
    "            job.download_files()\n",
    "            print(f\"\\n\")\n",
    "            asf_unzip(products_path, product)\n",
    "            print(f\"product: {product}\")\n",
    "            try:\n",
    "                os.remove(product)\n",
    "            except OSError:\n",
    "                pass\n",
    "            print(f\"\\nDone.\")\n",
    "        else:\n",
    "            print(f\"{filename} already exists.\")\n",
    "display(Markdown(f\"<text style=color:blue><text style='font-size:150%;'>ALL PRODUCTS DOWNLOADED</text></text>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine the available polarizations:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizations = get_RTC_polarizations(rtc_path)\n",
    "polarization_power_set = get_power_set(polarizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a polarization:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization_choice = select_parameter(sorted(polarization_power_set), 'Polarizations:')\n",
    "polarization_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a paths variable, holding the relative path to the tiffs in the selected polarization/s:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = polarization_choice.value\n",
    "print(polarization)\n",
    "if len(polarization) == 2:\n",
    "    regex = \"\\w[\\--~]{{5,300}}(_|-){}.(tif|tiff)$\".format(polarization)\n",
    "    dbl_polar = False\n",
    "else:\n",
    "    regex = \"\\w[\\--~]{{5,300}}(_|-){}(v|V|h|H).(tif|tiff)$\".format(polarization[0])\n",
    "    dbl_polar = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> You may notice duplicates in your acquisition dates. As HyP3 processes SAR data on a frame-by-frame basis, duplicates may occur if your area of interest is covered by two consecutive  image frames. In this case, two separate images are generated that need to be merged together before time series processing can commence.\n",
    "<br><br>\n",
    "<b>Write functions to collect and print the paths of the tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(regex, polarization, pths):\n",
    "    tiff_paths = []\n",
    "    for pth in glob.glob(pths):\n",
    "        tiff_path = re.search(regex, pth)\n",
    "        if tiff_path:\n",
    "            tiff_paths.append(pth)\n",
    "    return tiff_paths\n",
    "\n",
    "def print_tiff_paths(tiff_paths):\n",
    "    print(\"Tiff paths:\")\n",
    "    for p in tiff_paths:\n",
    "        print(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to collect the product acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(tiff_paths):\n",
    "    dates = []\n",
    "    for pth in tiff_paths:\n",
    "        dates.append(date_from_product_name(pth).split('T')[0])\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Collect and print the paths of the tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_pth = f\"{rtc_path}/*/*{polarization[0]}*.tif*\"    \n",
    "tiff_paths = get_tiff_paths(regex, polarization, tiff_pth)\n",
    "print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b>1.2 Fix multiple UTM Zone-related issues</b> <br>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Fix multiple UTM Zone-related issues should they exist in your data set. If multiple UTM zones are found, the following code cells will identify the predominant UTM zone and reproject the rest into that zone. This step must be completed prior to merging frames or performing any analysis.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Use gdal.Info to determine the UTM definition types and zones in each product:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_choice = select_parameter([\"UTM\", \"Lat/Long\"], description='Coord Systems:')\n",
    "coord_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_zones = []\n",
    "utm_types = []\n",
    "print('Checking UTM Zones in the data stack ...\\n')\n",
    "for k in range(0, len(tiff_paths)):\n",
    "    info = (gdal.Info(tiff_paths[k], options = ['-json']))\n",
    "    info = json.dumps(info)\n",
    "    info = (json.loads(info))['coordinateSystem']['wkt']\n",
    "    zone = info.split('ID')[-1].split(',')[1][0:-2]\n",
    "    utm_zones.append(zone)\n",
    "    typ = info.split('ID')[-1].split('\"')[1]\n",
    "    utm_types.append(typ)\n",
    "print(f\"UTM Zones:\\n {utm_zones}\\n\")\n",
    "print(f\"UTM Types:\\n {utm_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Identify the most commonly used UTM Zone in the data:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coord_choice.value == 'UTM':\n",
    "    utm_unique, counts = np.unique(utm_zones, return_counts=True)\n",
    "    a = np.where(counts == np.max(counts))\n",
    "    predominant_utm = utm_unique[a][0]\n",
    "    print(f\"Predominant UTM Zone: {predominant_utm}\")\n",
    "else:\n",
    "    predominant_utm = '4326'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Reproject all tiffs to the predominate UTM:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_indicies = [i for i, j in enumerate(utm_zones) if j != predominant_utm]\n",
    "print('--------------------------------------------')\n",
    "print('Reprojecting %4.1f files' %(len(reproject_indicies)))\n",
    "print('--------------------------------------------')\n",
    "for k in reproject_indicies:\n",
    "    temppath = tiff_paths[k].strip()\n",
    "    _, product_name, tiff_name = temppath.split('/')\n",
    "    cmd = f\"gdalwarp -overwrite rtc_products/{product_name}/{tiff_name}\"\\\n",
    "          f\" rtc_products/{product_name}/r{tiff_name} -s_srs {utm_types[k]}:\"\\\n",
    "          f\"{utm_zones[k]} -t_srs EPSG:{predominant_utm}\"\n",
    "    !$cmd\n",
    "    rm_cmd = f\"rm {tiff_paths[k].strip()}\"\n",
    "    !$rm_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update tiff_paths with any new filenames created during reprojection:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(regex, polarization, tiff_pth)\n",
    "print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b>1.3 Merge multiple frames from the same date.</b></font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a list aquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = get_dates(tiff_paths)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a set from the date list, removing any duplicates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = set(dates)\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine which dates have multiple frames. Create a dictionary with each date as a key linked to a value set as an empty string:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_date_batches = [{}]\n",
    "for date in unique_dates:\n",
    "    count = 0\n",
    "    for d in dates:\n",
    "        if date == d:\n",
    "            count +=1\n",
    "    if count > 1:\n",
    "        dup_date_batches[0].update({date : \"\"})\n",
    "if dbl_polar:\n",
    "    dup_date_batches.append(copy.deepcopy(dup_date_batches[0]))\n",
    "print(dup_date_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update the key values in dup_paths with the string paths to all the tiffs for each date:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dbl_polar:\n",
    "    polar_list = [polarization.split(' ')[0], polarization.split(' ')[2]]\n",
    "else:\n",
    "    polar_list = [polarization]\n",
    "\n",
    "for i, polar in enumerate(polar_list):\n",
    "    polar_regex = f\"(\\w|/)*_{polar}.(tif|tiff)$\"\n",
    "    polar_paths = get_tiff_paths(polar_regex, polar, tiff_pth)\n",
    "    for pth in polar_paths:\n",
    "        date = date_from_product_name(pth).split('T')[0]\n",
    "        if date in dup_date_batches[i]:\n",
    "            dup_date_batches[i][date] = f\"{dup_date_batches[i][date]} {pth}\"\n",
    "\n",
    "for d in dup_date_batches:\n",
    "    print(d)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Merge all the frames for each date.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dup_dates in enumerate(dup_date_batches):\n",
    "    for dup_date in dup_dates:\n",
    "        output = f\"{dup_dates[dup_date].split('/')[0]}/{dup_dates[dup_date].split('/')[1]}/new{dup_dates[dup_date].split('/')[2].split(' ')[0]}\"\n",
    "        gdal_command = f\"gdal_merge.py -o {output} {dup_dates[dup_date]}\"\n",
    "        print(f\"\\n\\nCalling the command: {gdal_command}\\n\")\n",
    "        !$gdal_command\n",
    "        for pth in dup_dates[dup_date].split(' '):\n",
    "            if pth and path_exists(pth):\n",
    "                os.remove(pth)\n",
    "                print(f\"Deleting: {pth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Verify that all duplicate dates were resolved:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(regex, polarization, tiff_pth)\n",
    "for polar in polar_list:\n",
    "    polar_tiff_pth = tiff_pth.replace('V*', polar)\n",
    "    polar_tiff_paths = get_tiff_paths(regex, polar, polar_tiff_pth)\n",
    "    dates = get_dates(polar_tiff_paths)\n",
    "    if len(dates) != len(set(dates)):\n",
    "        print(f\"Duplicate dates still present!\")\n",
    "    else:\n",
    "        print(f\"No duplicate dates are associated with {polar} polarization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the updated the paths to the tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a tiffs folder, move the tiffs into it, and delete the rtc_products folder:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_directory(\"tiffs\")\n",
    "for tiff in tiff_paths:\n",
    "    os.rename(tiff, f\"{analysis_directory}/tiffs/{tiff.split('/')[-1]}\")\n",
    "shutil.rmtree(rtc_path)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the path where you saved your tiffs.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{analysis_directory}/tiffs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Prepare_Data_Stack_Hyp3.ipynb - Version 4.4 - January 2021 \n",
    "    <br>\n",
    "        <b>Version Changes:</b>\n",
    "    <ul>\n",
    "        <li>Fix repeat downloading of already downloaded products</li>\n",
    "        <li>Update asf_notebook.get_power_set call</li> \n",
    "    </ul>\n",
    "    </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
