{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"7\"> <b> GEOS 657: Microwave Remote Sensing <b> </font>\n",
    "\n",
    "<font size=\"5\"> <b>Lab 7: Deep Learning in Earth Observation: Taizhou Change Detection </b> </font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Lichao Mou, German Aerospace Center; Xiaoxiang Zhu, German Aerospace Center & Technical University Munich </b> <br>\n",
    "</font>\n",
    "\n",
    "<img src=\"NotebookAddons/dlr-logo-png-transparent.png\" width=\"170\" align=\"right\" border=\"2\"/> <font size=\"3\"> This Lab introduces you to the basic concepts of Deep Learning in Earth Observation. Specifically, it uses Convolutional Recurrent Neural Networks (CRNNs) to perform a multi-temporal change detection on multispectral data collected over Taizhou, China. The images are both 400 Ã— 400 pixels in size and show significant changes mainly related to city expansion, soil change, and varying water areas.\n",
    "    \n",
    "We will again use a **Jupyter Notebook** framework implemented within the Amazon Web Services (AWS) cloud to work on this exercise. This Lab is part of the UAF course <a href=\"https://radar.community.uaf.edu/\" target=\"_blank\">GEOS 657: Microwave Remote Sensing</a>. It will introduce the following data analysis concepts:\n",
    "\n",
    "- How to set up a convolutional recurrent deep network within the Python-based <i>keras/tensorflow</i> environment\n",
    "- How to use CRNNs to perform change detection on multi-temporal remote sensing data \n",
    "</font>\n",
    "\n",
    "<font size=\"4\"> <font color='rgba(200,0,0,0.2)'> <b>There are no Homework assignments associated with this Notebook </b> </font>\n",
    "</font>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from keras.optimizers import Nadam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation - loading T1 and T2 images, training map, and test map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 3\n",
    "num_bands = 6\n",
    "print('########## load data... ##########')\n",
    "data = sio.loadmat('DL-data/Taizhou_3x3/TaizhouTm2000_norm.mat')\n",
    "imgT1 = np.float32(data['imgT1'])\n",
    "data = sio.loadmat('DL-data/Taizhou_3x3/TaizhouTm2003_norm.mat')\n",
    "imgT2 = np.float32(data['imgT2'])\n",
    "\n",
    "data = sio.loadmat('DL-data/Taizhou_3x3/TaizhouTraMapBinary.mat')\n",
    "tra_map = np.uint8(data['tra_map_binary'])\n",
    "data = sio.loadmat('DL-data/Taizhou_3x3/TaizhouTestMapBinary.mat')\n",
    "test_map = np.uint8(data['test_map_binary'])\n",
    "\n",
    "print('the shape of T1 image is: {}'.format(imgT1.shape))\n",
    "print('the shape of T2 image is: {}'.format(imgT2.shape))\n",
    "\n",
    "plt.imshow(imgT1[:, :, [3, 2, 1]])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgT2[:, :, [3, 2, 1]])\n",
    "plt.show()\n",
    "\n",
    "[rows, cols] = np.nonzero(tra_map)\n",
    "num_samples = len(rows)\n",
    "rows = np.reshape(rows, (num_samples, 1))\n",
    "cols = np.reshape(cols, (num_samples, 1))\n",
    "temp = np.concatenate((rows, cols), axis = 1)\n",
    "np.random.shuffle(temp)\n",
    "rows = temp[:, 0].reshape((num_samples,))\n",
    "cols = temp[:, 1].reshape((num_samples,))\n",
    "\n",
    "# sampling 3x3 patches as training samples according to the training map\n",
    "x_tra_t1 = np.float32(np.zeros([num_samples, patch_size, patch_size, num_bands])) # training samples from T1 image\n",
    "x_tra_t2 = np.float32(np.zeros([num_samples, patch_size, patch_size, num_bands])) # training samples from T2 image\n",
    "y_tra = np.uint8(np.zeros([num_samples,])) # ground truths for training samples\n",
    "for i in range(num_samples):\n",
    "    patch = imgT1[rows[i]-int((patch_size-1)/2) : rows[i]+int((patch_size-1)/2)+1, cols[i]-int((patch_size-1)/2) : cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_tra_t1[i, :, :, :] = patch\n",
    "    patch = imgT2[rows[i]-int((patch_size-1)/2) : rows[i]+int((patch_size-1)/2)+1, cols[i]-int((patch_size-1)/2) : cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_tra_t2[i, :, :, :] = patch\n",
    "    y_tra[i] = tra_map[rows[i], cols[i]]-1\n",
    "\n",
    "[rows, cols] = np.nonzero(test_map)\n",
    "num_samples = len(rows)\n",
    "rows = np.reshape(rows, (num_samples, 1))\n",
    "cols = np.reshape(cols, (num_samples, 1))\n",
    "temp = np.concatenate((rows, cols), axis = 1)\n",
    "np.random.shuffle(temp)\n",
    "rows = temp[:, 0].reshape((num_samples,))\n",
    "cols = temp[:, 1].reshape((num_samples,))\n",
    "\n",
    "# sampling 3x3 patches as test samples according to the test map\n",
    "x_test_t1 = np.float32(np.zeros([num_samples, patch_size, patch_size, num_bands])) # test samples from T1 image\n",
    "x_test_t2 = np.float32(np.zeros([num_samples, patch_size, patch_size, num_bands])) # test samples from T2 image\n",
    "y_test = np.uint8(np.zeros([num_samples,])) # ground truths for test samples\n",
    "for i in range(num_samples):\n",
    "    patch = imgT1[rows[i]-int((patch_size-1)/2) : rows[i]+int((patch_size-1)/2)+1, cols[i]-int((patch_size-1)/2) : cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_test_t1[i, :, :, :] = patch\n",
    "    patch = imgT2[rows[i]-int((patch_size-1)/2) : rows[i]+int((patch_size-1)/2)+1, cols[i]-int((patch_size-1)/2) : cols[i]+int((patch_size-1)/2)+1, :]\n",
    "    x_test_t2[i, :, :, :] = patch\n",
    "    y_test[i] = test_map[rows[i], cols[i]]-1\n",
    "\n",
    "print('the shape of input tensors on training set is: {}'.format(x_tra_t1.shape))\n",
    "print('the shape of target tensor on training set is: {}'.format(y_tra.shape))\n",
    "print('the shape of input tensors on training set is: {}'.format(x_test_t1.shape))\n",
    "print('the shape of target tensor on training set is: {}'.format(y_test.shape))\n",
    "print('##################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building up the recurrent convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.engine.input_layer import Input\n",
    "from keras.layers import Conv2D, Reshape, Activation, Concatenate, GRU, Dense, LSTM, SimpleRNN\n",
    "\n",
    "def build_network():\n",
    "    # the T1 branch of the convolutional sub-network\n",
    "    input1 = Input(shape = (3, 3, 6))\n",
    "    x1 = Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = 'valid')(input1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Reshape(target_shape = (1, 32))(x1)\n",
    "    \n",
    "    # the T2 branch of the convolutional sub-network\n",
    "    input2 = Input(shape = (3, 3, 6))\n",
    "    x2 = Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = 'valid')(input2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Reshape(target_shape = (1, 32))(x2)\n",
    "    \n",
    "    # the recurrent sub-network\n",
    "    x = Concatenate(axis = 1)([x1, x2])\n",
    "    #x = SimpleRNN(units = 128)(x)\n",
    "    x = LSTM(units = 128)(x)\n",
    "    #x = GRU(units = 128)(x)\n",
    "    x = Dense(units = 32, activation = 'relu')(x)\n",
    "    y = Dense(units = 1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    net = Model(inputs = [input1, input2], outputs = y)\n",
    "\n",
    "    net.summary()\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('########## train the network... ##########')\n",
    "batch_size = 32\n",
    "nb_epoch = 200\n",
    "net = build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadam = Nadam(lr = 0.00002)\n",
    "net.compile(optimizer = nadam, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "net_info = net.fit([x_tra_t1, x_tra_t2], y_tra, batch_size = batch_size, validation_split = 0.1, epochs = nb_epoch)\n",
    "\n",
    "loss = net_info.history['loss']\n",
    "loss_val = net_info.history['val_loss']\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "fig = plt.figure(figsize=(8,7))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.plot(loss)\n",
    "plt.plot(loss_val)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "#sio.savemat('loss_curves.mat', {'loss': loss, 'loss_val': loss_val})\n",
    "print('##########################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('########## test... ##########')\n",
    "# testing on test set\n",
    "score = net.evaluate([x_test_t1, x_test_t2], y_test)\n",
    "print(score[1])\n",
    "\n",
    "print('########## running on the whole image... ##########')\n",
    "cnt = 0\n",
    "x_t1 = np.float32(np.zeros([400*400, patch_size, patch_size, num_bands]))\n",
    "x_t2 = np.float32(np.zeros([400*400, patch_size, patch_size, num_bands]))\n",
    "print('sampling patches...')\n",
    "for i in range(1, imgT1.shape[0]-1, 1):\n",
    "    for j in range(1, imgT1.shape[1]-1, 1):\n",
    "        patch = imgT1[i-int((patch_size-1)/2) : i+int((patch_size-1)/2)+1, j-int((patch_size-1)/2) : j+int((patch_size-1)/2)+1, :]\n",
    "        x_t1[cnt, :, :, :] = patch\n",
    "        patch = imgT2[i-int((patch_size-1)/2) : i+int((patch_size-1)/2)+1, j-int((patch_size-1)/2) : j+int((patch_size-1)/2)+1, :]\n",
    "        x_t2[cnt, :, :, :] = patch\n",
    "        cnt = cnt + 1\n",
    "print('sampling done.')\n",
    "pred = net.predict([x_t1, x_t2])\n",
    "change_map_prob = np.reshape(pred, (400, 400))\n",
    "plt.imshow(change_map_prob)\n",
    "plt.show()\n",
    "\n",
    "change_map_binary = np.where(change_map_prob<0.5,0,1)\n",
    "plt.imshow(change_map_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
